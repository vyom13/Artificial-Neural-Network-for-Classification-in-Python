{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average_Error_Rate', 0.070000000000000007)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import division\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(np.concatenate((iris.data, np.array([iris.target]).T), axis=1), columns=iris.feature_names + ['target'])\n",
    "\n",
    "df1 = df.drop(df.index[0:50])\n",
    "df2 = df1.drop(['sepal length (cm)','sepal width (cm)'],axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "target = ['1', '2']\n",
    "\n",
    "m = df2.shape[0]\n",
    "\n",
    "n = 2  #features\n",
    "\n",
    "k = 2 #Number of classes\n",
    "\n",
    "X = np.ones((m,n + 1))\n",
    "y = np.array((m,1))\n",
    "X[:,1] = df2['petal length (cm)'].values\n",
    "X[:,2] = df2['petal width (cm)'].values\n",
    "\n",
    "\n",
    "y = df2['target'].values\n",
    "y=y-1\n",
    "#TO ignore the warnings given while scaling.\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "#Scaling the values between 0 and 1.\n",
    "for j in range(1,3):\n",
    "    X[:, j] = (X[:, j] - min(X[:,j]))/(max(X[:,j]) - min(X[:,j]))\n",
    "\n",
    "#Activation Function\n",
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))\n",
    "\n",
    "#Creating the first weight matrix with random values from 0 to 1.\n",
    "th1 = np.random.random((2,3))\n",
    "#Creating the second weight matrix with random values from 0 to 1.\n",
    "th2 = np.random.random((1,3))\n",
    "\n",
    "#function to calculate the a2 matrix\n",
    "def calculate_a2(X,th1):\n",
    "    z2 = np.dot(X,th1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.append(np.ones([len(a2),1]),a2,1)\n",
    "    return a2\n",
    "\n",
    "#function for predicting a2 \n",
    "def calculate_a2_prediction(X_test,th1):\n",
    "    z2 = np.dot(X_test.reshape(1,3),th1.T)\n",
    "    a2 = sigmoid(z2)\n",
    "    a2 = np.append(np.ones([len(a2),1]),a2,1)\n",
    "    return a2\n",
    "\n",
    "#function for calculating a3\n",
    "def calculate_a3(a2,th2):\n",
    "    z3 = np.dot(a2,th2.T)\n",
    "    a3 = sigmoid(z3)\n",
    "    return a3\n",
    "    \n",
    "\n",
    "def CostFunction(th2, a2, y):\n",
    "    m = len(y)\n",
    "    a3 = calculate_a3(a2,th2)\n",
    "    cost = (-1/m) * (y.T.dot(np.log(a3)) + (1 - y).T.dot(np.log(1 - a3)))\n",
    "    return cost\n",
    "\n",
    "def gradient_th2(th2,a2,X,y):\n",
    "    m,n = X.shape\n",
    "    a3 = calculate_a3(a2,th2)\n",
    "    delta = a3 - y.reshape(m,1)   \n",
    "    gradient = np.dot(np.transpose(delta),X)\n",
    "    gradient  = gradient/m\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def gradient_th1(th1,th2,a2,X,y):\n",
    "    m,n = X.shape\n",
    "    a2 = calculate_a2(X,th1)\n",
    "    a3 = calculate_a3(a2,th2)\n",
    "    delta2 = (a3 - y.reshape(m,1))\n",
    "    delta1 = np.multiply(np.dot(delta2,th2),np.multiply(a2,(1-a2)))\n",
    "    gradient = np.dot(np.transpose(delta1),X)\n",
    "    gradient = gradient[1:3,:]\n",
    "    gradient = gradient/m\n",
    "    return gradient    \n",
    "    \n",
    "\n",
    "\n",
    "def predictions(th1,th2,X):\n",
    "    a2 = calculate_a2_prediction(X,th1)\n",
    "    a3_predict = calculate_a3(th2,a2)\n",
    "    if (a3_predict >= 0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "\n",
    "total_error = 0\n",
    "\n",
    "    \n",
    "for k in range(100):\n",
    "    X_test = X[k,:]\n",
    "    X_train = np.delete(X,k,axis=0)\n",
    "    Y_train = np.delete(y,k)\n",
    "    Y_test = y[k]\n",
    "    th1 = np.random.random((2,3))\n",
    "    th2 = np.random.random((1,3))\n",
    "    list_cost = []\n",
    " \n",
    "\n",
    "       \n",
    "    for i in range(1000):\n",
    "        learning_rate = 0.5\n",
    "        a2 = calculate_a2(X_train,th1)\n",
    "        a3 = calculate_a3(a2,th2)\n",
    "        cost = CostFunction(th2,a2,Y_train)\n",
    "        gradient2 = gradient_th2(th2,a2,X_train,Y_train)\n",
    "        gradient1 = gradient_th1(th1,th2,a2,X_train,Y_train)\n",
    "        th2 -= np.multiply(learning_rate,gradient2)\n",
    "        th1 -= np.multiply(learning_rate,gradient1)\n",
    "        prediction = predictions(th1,th2,X_test)\n",
    "        error_each_iter = abs(Y_test - prediction)\n",
    "    total_error = total_error + error_each_iter\n",
    "Average_Error_Rate =     total_error/100.0\n",
    "print('Average_Error_Rate',Average_Error_Rate)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100L, 3L)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
